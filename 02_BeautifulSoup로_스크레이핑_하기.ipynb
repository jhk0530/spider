{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-BeautifulSoup로 스크레이핑 하기",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3oAAKQvuBd6I/EYWejlfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhk0530/spider/blob/master/02_BeautifulSoup%EB%A1%9C_%EC%8A%A4%ED%81%AC%EB%A0%88%EC%9D%B4%ED%95%91_%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfJXSkUCXg_8",
        "colab_type": "text"
      },
      "source": [
        "`BeautifulSoup` 는 xml, html 분석만 제공. 다운로드는 알아서 해야 됨\n",
        "\n",
        "## `BeautifulSoup` 설치\n",
        "\n",
        "파이썬 에서는 `pip`를 이용하여 패키지 설치함.\n",
        "\n",
        "* 추가로 colab에서는 install 할때 pip3 이렇게 쓰면 에러나고 대신 !pip3 이렇게 쓰면 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXmngM7GYdAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a31a32bc-9b72-42c9-db5a-f0eef3218601"
      },
      "source": [
        "!pip3 install beautifulsoup4\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# \"\"\" -> multiple line \n",
        "\n",
        "html = \"\"\" \n",
        "<html>\n",
        "  <body>\n",
        "    <h1 >스크레이핑이란</h1>\n",
        "    <p >웹 페이지를 분석 하는것</p>\n",
        "    <p>원하는 부분을 추출하는것</p>    \n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "h1 = soup.html.body.h1\n",
        "p1 = soup.html.body.p\n",
        "p2 = p1.next_sibling.next_sibling\n",
        "\n",
        "print(\"h1 = \" + h1.string)\n",
        "print(\"p1 = \" + p1.string)\n",
        "print(\"p2 = \" + p2.string)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "h1 = Header\n",
            "p1 = Paragraph 1\n",
            "p2 = Paragraph 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6wbS-BgaVZv",
        "colab_type": "text"
      },
      "source": [
        "`next_sibling`을 2번 쓰는 이유는 1번 쓰면 `<p>~</p>` 뒤의 있는 공백, nextline이 뽑힘\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdLILnRYamoS",
        "colab_type": "text"
      },
      "source": [
        "## `find` 함수를 사용해서 `id`로 element 찾기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEAKE0aYatif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5d6538da-4c03-48fc-dff1-a82953c26f62"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# \"\"\" -> multiple line \n",
        "\n",
        "html = \"\"\" \n",
        "<html>\n",
        "  <body>\n",
        "    <h1 id = 'title'>스크레이핑이란</h1>\n",
        "    <p id ='body'>웹 페이지를 분석 하는것</p>\n",
        "    <p>원하는 부분을 추출하는것</p>    \n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "title = soup.find(id = 'title')\n",
        "body = soup.find(id = 'body')\n",
        "\n",
        "print(\"#title = \" + title.string)\n",
        "print('#body = ' + body.string)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#title = 스크레이핑이란\n",
            "#body = 웹 페이지를 분석 하는것\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLlgSrQlbIbr",
        "colab_type": "text"
      },
      "source": [
        "## `find_all`을 사용하여 여러개의 element 추출하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNDdOxfpbL5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "31bba352-2227-41ce-b65a-f1bb19b80968"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html =\"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "  <ul>\n",
        "    <li><a href = 'http://www.naver.com'>naver</a></li>\n",
        "    <li><a href = 'http://www.daum.net'>daum</a></li>\n",
        "  </ul>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "links = soup.find_all('a')\n",
        "\n",
        "for a in links:\n",
        "  href = a.attrs['href']\n",
        "  text = a.string\n",
        "  print(text, '>', href)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naver > http://www.naver.com\n",
            "daum > http://www.daum.net\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KhfC3KzdVlx",
        "colab_type": "text"
      },
      "source": [
        "## DOM element 속성에 대하여\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWXG9RswdYhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "7510934f-6226-4aca-c7ff-ca3816c806eb"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(\n",
        "    \"<p><a href = 'a.html'>text</a></p>\", 'html.parser'\n",
        ")\n",
        "\n",
        "print(soup.prettify())\n",
        "\n",
        "a = soup.p.a\n",
        "\n",
        "print(type(a.attrs))\n",
        "\n",
        "print('href' in a.attrs)\n",
        "\n",
        "a['href']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<p>\n",
            " <a href=\"a.html\">\n",
            "  text\n",
            " </a>\n",
            "</p>\n",
            "<class 'dict'>\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a.html'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSiXcd27exV3",
        "colab_type": "text"
      },
      "source": [
        "## `urlopen` 와 `BeautifulSoup` 조합하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBSD9wPqfUbR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ac22dd46-6dce-40b5-d309-bafcab565372"
      },
      "source": [
        "import urllib.request as req\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
        "\n",
        "res = req.urlopen(url)\n",
        "\n",
        "soup = BeautifulSoup(res, 'html.parser')\n",
        "\n",
        "title = soup.find('title').string\n",
        "wf = soup.find('wf').string\n",
        "print(title)\n",
        "print(wf)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기상청 육상 중기예보\n",
            "○ (강수) 8일(수)은 강원영동에 비가 오겠습니다.<br />○ (건조) 이번 예보기간(8~15일) 전국이 대체로 맑고 대기가 매우 건조하겠으니, 산불 등 화재예방에 각별히 유의하기 바랍니다.<br />○ (기온) 이번 예보기간(8~15일) 낮 기온은 어제(4일, 9~23도)보다 조금 높거나 비슷한 13~22도로 포근하겠습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHJU1El4h0fl",
        "colab_type": "text"
      },
      "source": [
        "## CSS Selector 사용하기\n",
        "\n",
        "```python\n",
        "soup.select_one() # 1개\n",
        "soup.select()  # 여러개\n",
        "```\n",
        "로 추출 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMm2LcxVi2NH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f032c826-592c-465a-b1fe-d4d7284a14b8"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "<div id ='meigen'>\n",
        "<h1>위키북스 도서</h1>\n",
        "<ul class='items'>\n",
        "<li> 유니티 게임 이펙트 입문</li>\n",
        "<li> 스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
        "<li> 모던 웹사이트 디자인의 정석</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "h1 = soup.select_one('#meigen > h1').string\n",
        "print(\"h1= \",h1)\n",
        "\n",
        "li_list = soup.select('.items > li')\n",
        "for li in li_list:\n",
        "  print(\"li = \", li.string)\n",
        "\n",
        "# div, ul 이런거 필요에 따라서 생략 가능 (selector 지정가능하다면)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h1=  위키북스 도서\n",
            "li =   유니티 게임 이펙트 입문\n",
            "li =   스위프트로 시작하는 아이폰 앱 개발 교과서\n",
            "li =   모던 웹사이트 디자인의 정석\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwrJhopikJFs",
        "colab_type": "text"
      },
      "source": [
        "## 네이버 금융에서 환율 정보 추출하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKX9Q1EBkPGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e784e9e-373b-4910-dcd3-bd88787d2583"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request as req\n",
        "\n",
        "url = 'https://finance.naver.com/marketindex/?tabSel=exchange#tab_section'\n",
        "\n",
        "res = req.urlopen(url)\n",
        "\n",
        "soup = BeautifulSoup(res, 'html.parser')\n",
        "\n",
        "price = soup.select_one('.head_info.point_up > span.value').string\n",
        "print('usd/krw = ', price)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usd/krw =  1,236.00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}