{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "71-유사 이미지 검출하기",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOD7Ldu3pADWdP8YTCnUaPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhk0530/spider/blob/master/71_%EC%9C%A0%EC%82%AC_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EA%B2%80%EC%B6%9C%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ_EazkF1en5",
        "colab_type": "text"
      },
      "source": [
        "## 이미지 인식 - Average Hash\n",
        "\n",
        "`Average Hash`란, 이미지를 비교 가능한 해시 값으로 나타내는것, 해시함수 `MD5`, `SHA256`등을 이용하여 변환.\n",
        "\n",
        "그러나 이미지가 비슷한지 검출할때는 사용하면 안됨 이유는 이미지데이터에\n",
        "\n",
        "- 해상도 조절\n",
        "- 색 보정\n",
        "- PNG 등 형식 변경등으로 인해\n",
        "\n",
        "완전한 바이너리를 찾는것이 어려움.\n",
        "\n",
        "이로 인해 이미지가 조금 밝게 혹은 어둡게처럼 약간 변경후에도 이미지를 비교 할 경우 `Average Hash`를 사용함\n",
        "\n",
        "예시 프로세스 과정\n",
        "\n",
        "- 이미지를 8x8 사이즈로 축소 시킴\n",
        "- 색을 그레이스케일로 변환\n",
        "- 이미지의 각 픽셀의 평균을 계산하여 평균보다 크면 1, 작으면 0을 반환 \n",
        "\n",
        "이렇게 하면 이미지마다 64비트의 해시 값을 구할 수 있음.\n",
        "\n",
        "사용하는 library는 `pillow`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NudcXZ0n2ZtA",
        "colab_type": "code",
        "outputId": "235b5a44-8442-4ee4-8b30-8c3ee7f312fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip3 install Pillow\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUD1eE395aic",
        "colab_type": "code",
        "outputId": "e8f9819c-c785-4b11-e37b-ec76bbf378ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 파일 다운로드\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "url = 'https://yotsuya.hotelkeihan.co.jp/wp-content/uploads/sites/394/2019/02/Tokyo-Tower-500x250.jpg'\n",
        "\n",
        "savename  ='tower.jpg'\n",
        "urllib.request.urlretrieve(url, savename)\n",
        "\n",
        "print('저장되었습니다...!')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "저장되었습니다...!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osw6ZW8t2e8Q",
        "colab_type": "code",
        "outputId": "535fb2ae-f7bc-4d06-cec4-a7a4836abb17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def average_hash (fname, size = 16):\n",
        "  img = Image.open(fname)\n",
        "  img = img.convert('L') # 그레이 스케일로 변환\n",
        "  img = img.resize((size,size), Image.ANTIALIAS) # 리사이즈\n",
        "  \n",
        "  pixel_data = img.getdata() # 픽셀값\n",
        "  pixels = np.array(pixel_data) # numpy로 치환\n",
        "  pixels = pixels.reshape((size, size)) # 2 차원으로 변환\n",
        "\n",
        "  avg = pixels.mean()\n",
        "  diff = 1* (pixels>avg)\n",
        "\n",
        "  return diff\n",
        "\n",
        "def np2hash(ahash):\n",
        "  bhash  =[]\n",
        "  \n",
        "  for nl in ahash.tolist():\n",
        "    s1 = [str(i) for i in nl]\n",
        "    s2 = ''.join(s1)\n",
        "    i = int(s2,2)\n",
        "    bhash.append('%04x' % i)\n",
        "  \n",
        "  return \"\".join(bhash)\n",
        "\n",
        "ahash = average_hash('tower.jpg')\n",
        "print(ahash)\n",
        "print(np2hash(ahash))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1]\n",
            " [0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1]\n",
            " [0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1]\n",
            " [0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1]\n",
            " [0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1]\n",
            " [0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1]]\n",
            "0380038007c00780038007c006400f600f210f01060305070d0701170d1f0f0f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdBCQ0jl5-Z_",
        "colab_type": "code",
        "outputId": "ecf16271-5686-4064-c9a3-e6f99a20f89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# CALTECH Data URL = http://www.vision.caltech.edu/Image_datasets/Caltech101/Caltech101.html\n",
        "\n",
        "# http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "os.getcwd() # /content\n",
        "\n",
        "#import urllib.request\n",
        "\n",
        "#url = 'http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz'\n",
        "\n",
        "#savename  ='101_ObjectCategories.tar.gz'\n",
        "#urllib.request.urlretrieve(url, savename)\n",
        "\n",
        "# print('저장되었습니다...!')\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogHmf2Yx-vNM",
        "colab_type": "text"
      },
      "source": [
        "데이터 저장하려는데 디렉토리 구조가 안보임 ㅅㄱ\n",
        "\n",
        "파일 `contents` 잘못 옮겨서 터진거였다\n",
        "초기화 하려면, 노트 새로 만들기 하지말고 그냥 런타임 초기화 하면 됨 ~\n",
        "\n",
        "데이터는 다 쓰는게 아닌 yinyang 음양만 씀\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R95ZKE41CEzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "0b48f8ba-5669-4e72-f13b-226a27785eea"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os, re\n",
        "\n",
        "search_dir = './'\n",
        "cache_dir = './cache_avhash'\n",
        "\n",
        "# 캐시 디렉토리 생성\n",
        "if not os.path.exists(cache_dir):\n",
        "  os.mkdir(cache_dir)\n",
        "\n",
        "def average_hash(fname, size = 16):\n",
        "  fname2 = fname[len(search_dir):]\n",
        "\n",
        "  cache_file = cache_dir + '/' + fname2.replace('/', '_')+ \".csv\"\n",
        "  \n",
        "  if not os.path.exists(cache_file):# 캐시 없는 경우, 생성\n",
        "    img = Image.open(fname)\n",
        "    img = img.convert('L').resize((size,size), Image.ANTIALIAS)\n",
        "    pixels = np.array(img.getdata()).reshape((size,size))\n",
        "    avg = pixels.mean()\n",
        "    px = 1*(pixels>avg)\n",
        "    np.savetxt(cache_file, px, fmt = '%.0f', delimiter = ',')\n",
        "  else : \n",
        "    px = np.loadtxt(cache_file, delimiter=',')\n",
        "\n",
        "  return px\n",
        "\n",
        "\n",
        "def hamming_dist(a,b):\n",
        "  aa = a.reshape(1,-1)\n",
        "  ab = b.reshape(1,-1)\n",
        "  dist = (aa!=ab).sum()\n",
        "  return dist\n",
        "\n",
        "def enum_all_files(path):\n",
        "  for root,dirs, files in os.walk(path):\n",
        "    for f in files:\n",
        "      fname = os.path.join(root,f)\n",
        "      if re.search(r'\\.(jpg|jpeg|png)$', fname):\n",
        "        yield fname\n",
        "\n",
        "def find_image(fname, rate):\n",
        "  src = average_hash(fname)\n",
        "  for fname in enum_all_files(search_dir):\n",
        "    dst = average_hash(fname)\n",
        "    diff_r = hamming_dist(src,dst) / 256\n",
        "    if diff_r < rate : \n",
        "      yield(diff_r, fname)\n",
        "\n",
        "srcfile = search_dir+'image_0016.jpg'\n",
        "html = ''\n",
        "sim = list(find_image(srcfile,0.25))\n",
        "sim = sorted(sim, key = lambda x:x[0])\n",
        "for r,f in sim:\n",
        "  print(r,'>',f)\n",
        "  s = \"<div style='float:left'><h3>[차이 : \" + str(r) + ' - ' + os.path.basename(f) + ']</h3>' + '<p><a href = \"' + f + '\"> <img src=\"' +f+ '\" width = 400>'+ '</a></p></div>'\n",
        "  html += s\n",
        "\n",
        "html = \"\"\"<html>\n",
        "<head><meta charset = 'utf8'></head>\n",
        "<body>\n",
        "  <h3>원래 이미지 <h3>\n",
        "  <p><img src='{0}'> width = 400></p>{1}\n",
        "</body>\n",
        "</html>\"\"\".format(srcfile,html)\n",
        "with open('./avhash-search-output.html', 'w', encoding = 'utf-8') as f :\n",
        "  f.write(html)\n",
        "\n",
        "print(\"ok\")\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 > ./image_0016.jpg\n",
            "0.16015625 > ./image_0028.jpg\n",
            "0.16796875 > ./image_0030.jpg\n",
            "0.19140625 > ./image_0021.jpg\n",
            "0.21875 > ./image_0008.jpg\n",
            "0.23046875 > ./image_0044.jpg\n",
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXp7JfSCHpQr",
        "colab_type": "text"
      },
      "source": [
        "html 리포트가 잘 안나오긴 하지만 어쨌던, 이미지 비교 - 분석은 잘 됨."
      ]
    }
  ]
}